# MEMO

# ニューラルネットワークが学習するために

## 損失関数が必要
これは指標
できるだけ小さな値がでるように､探しだす｡

## 特徴を抽出する必要がある
### 機械学習の場合は
データをベクトルに変更する際に､人が設計した特徴量を用いる｡

### ニューラルネットワークは
そのまま学習する

#### 訓練データ テストデータ
訓練データを用いて､データの学習を行い最適なパラメータを探索する｡
テストデータを用いて､評価

教師データは訓練データと同義

#### 過学習(Over fitting)
ひとつのデータセットだけで､学習と評価をおこなってると一部のデータセットに過度に適応された状態になってしまうことがある｡

## 損失関数(loss function)_
指標
現在の状態を把握するために､指標を使う｡
それを基準として､最適な重みパラメーターの探索を行う｡

### 二乗和誤差

教師データを[0, 0, 1, 0, 0]
のようにもち
結果を[0.01, 0.05, 0.8, 0.05, 0.1]
のように持つものとする｡

教師データと､実行結果の差の2乗を総和する｡

### 交差エントロピー誤差
二乗和誤差と同様に計算式にあてはめて､試す｡

## ミニバッチ学習
大量にあるデータから､無作為に少しだけ抜き出して学習を行う


# 学習アルゴリズムの実装方法
確率的勾配降下法

-> 確率的に無作為に選び出したデータに対して行う勾配降下法



## ミニバッチ
訓練データから､ランダムにデータをえらぶ

## 勾配算出
ミニバッチの損失関数を減らすため､重みパラメータの勾配をきめる

## パラメータの更新
重みパラメータを勾配方向に微小量増加させる

## 繰り返す




